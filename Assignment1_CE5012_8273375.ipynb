{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0od727REF6w"
   },
   "source": [
    "#Assignment 1: Vision Transformer\n",
    "In this lab you will build a vision transformer and train it on the CIFAR-10 dataset.\n",
    "![](https://github.com/tonyscan6003/etivities/blob/main/vit.JPG?raw=true)\n",
    "\n",
    "A key problem with using transformers with images is long sequence lengths when each pixel is used as an individual token. As the computational complexity of transformers scales quadratically with sequence length, approaches to reduce the computation are required. The vision transformer solves this problem by dividing the image into a shorter sequence of patches that are converted to tokens with a dimension D.\n",
    "\n",
    "Unlike convolution which inherently retains spatial information, the transformer self attention mechanism will compute the same result regardless of the order of the tokens. For this reason a sinusoidal positional encoding is included to retain positional information.  \n",
    "\n",
    "The vision transformer can be trained on CIFAR-10 using supervised learning. A final classification layer is applied to the learned classification token. (We note that due to self attention, this token obtains information from the input patches and can therefore determine the class)\n",
    "\n",
    "Note on this assignment:\n",
    "* The goal of the assignment is to successfully code the transformer (not to achieve high the highest possible performance or optimise the training).  \n",
    "* The Projection of the patches and positional encoding blocks is given in the notebook.\n",
    "* It is recommended to take a hierachical approach to building the vision transformer.\n",
    " * Start with the lowest level self-attention block, then add multi-head attention, the transformer encoder and finally a toplevel vision transformer block.\n",
    " * Each block can be structured as a sub-class of nn.module. Instances of these classes can then be called into classes for higher level blocks (e.g. multi-head attention will create instances of the attention block)  \n",
    " * Take particular care with the dimensions of the token tensors. The pytorch layers such as nn.linear operate on the last dimension of the tensor. Therefore we want the features of the token (\"D\" dimension) to the be the last dimension.\n",
    " * You may want to initally use a small dimensionality D in your model when de-bugging as it will run more quickly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DEt0NrOfEBpA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models\n",
    "from torchvision.transforms import ToTensor, v2, Pad\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1677,
     "status": "ok",
     "timestamp": 1739982514325,
     "user": {
      "displayName": "Tony Scanlan",
      "userId": "11380187689366571663"
     },
     "user_tz": 0
    },
    "id": "9Dx_DK31F4gR",
    "outputId": "d976aecf-fbd2-4279-a055-e11039cefb41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j8BOvrQ5_dE2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA RTX 4000 Ada Generation\n",
      "__CUDNN VERSION: 90400\n",
      "__Number CUDA Devices: 1\n",
      "__CUDA Device Name: NVIDIA RTX 4000 Ada Generation\n",
      "__CUDA Device Total Memory [GB]: 21.469069312\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if not use_cuda:\n",
    "\texit()\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)\n",
    "print('Memory Usage:')\n",
    "print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S65n7FefE5T7"
   },
   "source": [
    "## Import Dataset\n",
    "The [torchvision](https://pytorch.org/vision/stable/index.html) package (imported above) makes available several common image classification, object detection, semantic segmentation datasets, aswell as other [datasets](https://pytorch.org/vision/stable/datasets.html) for common computer vision applications.  \n",
    "\n",
    "You can adjust these transforms as part of your regularisation strategy for the network. (Note that only the train_transform should be modified, we don't want to apply augmentation to the test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kj3lHLmyl-AR"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "train_transforms = v2.Compose([\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    ToTensor(),\n",
    "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "test_transforms = v2.Compose([\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    ToTensor(),\n",
    "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "'''\n",
    "\n",
    "train_transforms = v2.Compose([\n",
    "    v2.RandomResizedCrop(size=32,scale=(0.8,1.0)),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    ToTensor(),\n",
    "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "test_transforms = v2.Compose([\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    ToTensor(),\n",
    "    v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "#v2.RandomRotation(degrees=(-45, 45)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CGcCuvXjE7TI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transforms,\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LH_kTIFYIoTA"
   },
   "source": [
    "The `Dataset` is passed as an argument to `DataLoader`. This wraps an\n",
    "iterable over the dataset, and supports automatic batching, sampling,\n",
    "shuffling and multiprocess data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1739982515489,
     "user": {
      "displayName": "Tony Scanlan",
      "userId": "11380187689366571663"
     },
     "user_tz": 0
    },
    "id": "bX-snmo0Iv3v",
    "outputId": "4b4fecab-8555-4178-8287-742c7c9d48fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([256, 3, 32, 32])\n",
      "Shape of y: torch.Size([256]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "batch_size = 256\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "K5iqVbNpQAOH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Samples  10000\n",
      "Train Samples  50000\n",
      "Test Batches  40\n",
      "Train Batches  196\n"
     ]
    }
   ],
   "source": [
    "print('Test Samples ',len(test_dataloader.dataset))\n",
    "print('Train Samples ',len(train_dataloader.dataset))\n",
    "print('Test Batches ',len(test_dataloader))\n",
    "print('Train Batches ',len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "L8VjVE0CmZYw"
   },
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "\n",
    "def plot_examples(image_batch,labels_batch,pred_labels_batch):\n",
    "  n_plots = 12 # number of plots\n",
    "  f, axarr = plt.subplots(1,n_plots,figsize=(20,10))\n",
    "\n",
    "  for i, image in enumerate(image_batch[0:n_plots,:,:,:]):\n",
    "    # return image to cpu for display and permute to channels last\n",
    "    disp_image =  torch.permute(image.to('cpu'),(2,1,0)).numpy()\n",
    "\n",
    "    # Correct mean/std for display\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    disp_image = std * disp_image + mean\n",
    "    disp_image = np.clip(disp_image, 0, 1)\n",
    "\n",
    "    #\n",
    "    axarr[i].imshow(disp_image[:,:,:])\n",
    "    axarr[i].axis(\"off\")\n",
    "    #predicted, actual = classes[pred_labels_batch[0,i]], classes[labels_batch[i]]\n",
    "    predicted, actual = classes[pred_labels_batch.to('cpu')[i]], classes[labels_batch.to('cpu')[i]]\n",
    "    color = 'black' if predicted == actual else 'red'\n",
    "    axarr[i].set_title(predicted,fontsize='small', color=color)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1739982516094,
     "user": {
      "displayName": "Tony Scanlan",
      "userId": "11380187689366571663"
     },
     "user_tz": 0
    },
    "id": "C558MSNYQxd8",
    "outputId": "f1e323af-2b5e-4fb0-bbd3-9f072702a6d3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Output next batch from dataloader\n",
    "dataiter = iter(train_dataloader)\n",
    "image_batch, labels_batch = next(dataiter)\n",
    "\n",
    "# Call plot with pred_label_batch = labels_batch before training\n",
    "plot_examples(image_batch,labels_batch,labels_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIIjqCm9IbxS"
   },
   "source": [
    "# Define Transformer Model\n",
    "\n",
    "It is necssary to define a series of blocks to train the transformer model\n",
    "\n",
    "\n",
    "*   1. Patch Embedding (included)\n",
    "*   2. Positional Encoding (included)\n",
    "*   3. Attention block\n",
    "*   4. Multi head attention\n",
    "*   5. Transformer Encoder\n",
    "*   6. Vision Transformer (top level)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xlh_-xf9QJ"
   },
   "source": [
    "1. Patch Embedding:\n",
    "\n",
    "This block could be implemented by first dividing the the image into patches (with an image processing function) and then applying the same linear layer to each patch. However this block is most efficiently implemented as a convolution followed by permute and flatten operations which achieves the same result.\n",
    "* The convolution applies the same set of weights to a patch of the image. converting the patch to an embedding or token (after permute and flatten operations) . The number of kernels used in the convolution sets the dimensionality of the token.\n",
    "* The convolution uses a large patch size and a stride equal to the patch size. The number of patches sets the number of tokens at the input to the vision transformer.\n",
    "* The number of patches to be used can be determined from the guide to convolutional arithmetic (relationship no 5. No zero padding,non-unit strides) o = (i-k)/s +1 the ouptut size (for one dimension). We typically try to choose the patch size so that an integer number of patches are obtained. For example if i=32, and if we choose a patch size of k=8, and using the same stride as the patch size s=8 (no overlapping) then o=(32-8)/8+1=24/8+1=3+1=4 so there will be 4 patches along each dimension of the input image (so 16 patches in total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Ueg_O_k1_DcF"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Patch_embedding(nn.Module):\n",
    "    def __init__(self,in_channels,d_transformer,patch_size):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels       # number of channels (C) in input\n",
    "        self.d_transformer = d_transformer   # number of dimensions (D) in token (same as number of kernels in convolution)\n",
    "        self.patch_size = patch_size         # Size of patch in pixels\n",
    "\n",
    "        self.conv = nn.Conv2d(self.in_channels,self.d_transformer,self.patch_size,stride=self.patch_size,padding='valid')\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        int_1 = self.conv(x)  # Input B x C x n x m converted to B x D x m'x n'\n",
    "                              # where m' and n' is spatial size after convolution\n",
    "\n",
    "        int_2 = torch.permute(int_1,(0,2,3,1))  # Use permute to make channels last B x m'x n' x D\n",
    "        emb = torch.flatten(int_2,start_dim=1,end_dim=2)  # Flattent to B x N x D where N is sequence length (equal to no patches)\n",
    "        return emb\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Baqq9ERdrMmh"
   },
   "source": [
    "2. Positional Encoding\n",
    "\n",
    "* A good explanation for positional encoding and the use of sinusoidal functions to achieve this is detailed in the [hugginface blog](https://huggingface.co/blog/designing-positional-encoding). The matrix of positional values `pi_matrix` is created using torch cos and sin functions.\n",
    "* We note that this matrix is assigned as [register_buffer](https://discuss.pytorch.org/t/what-is-the-difference-between-register-buffer-and-register-parameter-of-nn-module/32723). This allows us to use this matrix of values in the model (on the GPU), but they are not stored as learned parameters.\n",
    "\n",
    "* Finally we note that this block creates the classification token. This token is defined as learned parameter using [nn.parameter](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html). The classification token will increase the number of tokens by 1 over the number of patches. This token is passed through the self-attention blocks and receives information from other patches. It can be used to predict classes at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IAAuVGVV8-x6"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Positional_encoding(nn.Module):\n",
    "    def __init__(self,d_transformer,n_patches):\n",
    "        super().__init__()\n",
    "        self.D = d_transformer   # number of dimensions (D) in token\n",
    "        self.n_patches = n_patches   # number of patches in input\n",
    "        self.N = self.n_patches+1     # number of tokens (N) in sequence including CLS token\n",
    "\n",
    "        self.class_token = torch.nn.Parameter(torch.randn(1, 1, self.D))   # Learned embedding token\n",
    "\n",
    "        # Create matrix PI of values that can be multiplied against the input token x in forward method\n",
    "        # Matrix must be of size B x N x D\n",
    "        pi_matrix = torch.zeros(self.N,self.D)\n",
    "        for pos in range(self.N):\n",
    "            for i in range(self.D):\n",
    "              if i % 2 == 0:\n",
    "                pi_matrix[pos,i] = torch.cos(torch.tensor(pos/(10000**(2*i/self.D))))\n",
    "              else:\n",
    "                pi_matrix[pos,i] = torch.sin(torch.tensor(pos/(10000**(2*i/self.D))))\n",
    "\n",
    "        self.register_buffer('pi_matrix', pi_matrix, persistent = False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expand the cls tensor across the batch dimension and contactenate with input\n",
    "        exp_cls = self.class_token.expand(x.size()[0], -1, -1)\n",
    "        x = torch.cat((exp_cls,x),dim=1)\n",
    "        # Add the positional encoding to the input tokens\n",
    "        mult_pe = x+self.pi_matrix\n",
    "\n",
    "        return mult_pe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 16, 24])\n"
     ]
    }
   ],
   "source": [
    "numChannels = 3\n",
    "patchSize = 8\n",
    "numDims = 24\n",
    "\n",
    "PatchEmbedding = Patch_embedding(numChannels,numDims,patchSize)\n",
    "emb = PatchEmbedding(image_batch)\n",
    "print(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 17, 24])\n"
     ]
    }
   ],
   "source": [
    "PositionalEncoding = Positional_encoding(24,16)\n",
    "pe = PositionalEncoding(emb)\n",
    "print(pe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC53f0qT3i-V"
   },
   "source": [
    "3. Attention Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yK0JfKDQu_Pe"
   },
   "outputs": [],
   "source": [
    "# Class to define attention head\n",
    "# step 1. Operates on a sequence of tokens of size K=8 x1 to xn where n = 17 \n",
    "# step 2. Learned weights for Q,K,V\n",
    "# step 3. dot product ok K.T with Q\n",
    "#step 4. Normalise attention\n",
    "# step 5 Scalar multiply of V with attention  \n",
    "\n",
    "class attentionHead(nn.Module):\n",
    "    def __init__(self,embSize,numHeads,numPatchs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.D = int(embSize/numHeads)\n",
    "        self.P = numPatchs\n",
    "        self.Q = nn.Linear(self.D,self.D)\n",
    "        self.K = nn.Linear(self.D,self.D)\n",
    "        self.V = nn.Linear(self.D,self.D)\n",
    "        print(\"selfs \",self.D,self.P)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        q = self.Q(x)\n",
    "#        print(\"q is \",q)\n",
    "        k = self.K(x)\n",
    "        v = self.V(x)\n",
    " \n",
    "        kTranspose = k.T\n",
    "#        print(\"shapes \", kTranspose.shape,q.shape)\n",
    "# dot product of K.T with q\n",
    "#        kq_scaled = torch.mm(kTranspose,q) / np.sqrt(self.tokenLength)\n",
    "#        kq_scaled = torch.mm(q,kTranspose) / np.sqrt(self.tokenLength)\n",
    "        kq_scaled = torch.bmm(q,k.transpose(1,2))\n",
    "\n",
    "        \n",
    "        normedAttn = nn.functional.softmax(kq_scaled,dim=1)\n",
    "\n",
    "#        print(\"kq is \",kq_scaled)\n",
    "\n",
    "#        print(\"normed attn \",normedAttn)\n",
    "\n",
    "        SA_X = torch.bmm(normedAttn,v)\n",
    "\n",
    "#        print(\"SA[x] \", SA_X.shape)\n",
    "\n",
    "        \n",
    "\n",
    "        return SA_X\n",
    "\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyk7--yK3lrY"
   },
   "source": [
    "4. Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PNSkeisPZGS-"
   },
   "outputs": [],
   "source": [
    "\n",
    " class MultiHeadattention(nn.Module):\n",
    "    def __init__(self,tokenLength,numHeads,numPatchs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.D = tokenLength \n",
    "        self.H = numHeads\n",
    "        self.P = numPatchs\n",
    "        embSize = int(self.D/self.H)\n",
    "#        print(\"embsize \",embSize)\n",
    "        self.mha = nn.ModuleList([attentionHead(self.D,self.H,self.P) for i in range(self.H)])\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        splitX = torch.tensor_split(x,self.H,dim=2)\n",
    "        i = 0\n",
    "        splitOutputs = []\n",
    "        for attnhead in self.mha:\n",
    "            splitOutputs.append(attnhead(splitX[i]))\n",
    "#            print(\"splitx shape \",splitX[i].shape)\n",
    "            i = i + 1                    \n",
    "\n",
    "            \n",
    "        SA = torch.cat(splitOutputs,dim=-1)\n",
    "\n",
    "        \n",
    "\n",
    "        return SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selfs  12 16\n",
      "selfs  12 16\n",
      "torch.Size([256, 16, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_630/2306292312.py:25: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3683.)\n",
      "  kTranspose = k.T\n"
     ]
    }
   ],
   "source": [
    "MHSA=MultiHeadattention(24,2,16)\n",
    "SA = MHSA(emb)\n",
    "print(SA.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lb_k3VruvTjm"
   },
   "source": [
    "5. Transformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Rq3acp8rjBlT"
   },
   "outputs": [],
   "source": [
    " class TransformerEncoder(nn.Module):\n",
    "    def __init__(self,embSize,numHeads,numPatchs):\n",
    "        super().__init__()\n",
    "        self.D = embSize\n",
    "        self.H = numHeads\n",
    "        self.P = numPatchs\n",
    "        self.normLayer1 = nn.LayerNorm(self.D)\n",
    "        self.MHA_Layer=MultiHeadattention(self.D,self.H,self.P)\n",
    "        self.normLayer2 = nn.LayerNorm(self.D)\n",
    "        nn.Dropout(p=0.2)\n",
    "        self.feedForward = nn.Sequential(\n",
    "            nn.Linear(self.D,self.D),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(self.D,self.D))         \n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "#        print(\"pe shape \", x.shape)\n",
    "#        print(\"xshape \",x.shape,self.D)\n",
    "\n",
    "#        print(\"TE \", x.shape)\n",
    "        xNorm = self.normLayer1(x)\n",
    "        MHSA = self.MHA_Layer(xNorm)\n",
    "        x = self.normLayer2(x+MHSA)\n",
    "#        print(\"mhsa \",MHSA.shape)\n",
    "        ffLayer = self.feedForward(x)\n",
    "\n",
    "\n",
    "        return x\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selfs  12 16\n",
      "selfs  12 16\n"
     ]
    }
   ],
   "source": [
    "te = TransformerEncoder(24,2,16)\n",
    "x = te(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKrd-yUGvRfA"
   },
   "source": [
    "6. Vision Transformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "ZKzMO9-nVjaR"
   },
   "outputs": [],
   "source": [
    "class Vision_transformer(nn.Module):\n",
    "    def __init__(self,numChannels,numDims,patchSize,NumPatches,numHeads,numClasses,numLayers):\n",
    "        super().__init__()\n",
    "        self.C = numChannels   # number of channels\n",
    "        self.D = numDims   # number of dimensions (D) in token\n",
    "        self.H = numHeads  # number of heads in multihead attention\n",
    "        self.P = patchSize  \n",
    "        self.NP = numPatches # number of patches in input\n",
    "        self.CLS = numClasses # \n",
    "        self.L = numLayers\n",
    "        self.N = self.P+1     # number of tokens (N) in sequence including CLS token\n",
    "\n",
    "        self.embeddingLayer =  Patch_embedding(self.C,self.D,self.P)\n",
    "        self.PELayer = Positional_encoding(self.D,self.NP)\n",
    "        transformerBlocks = [TransformerEncoder(self.D,self.H,self.P) for _ in range(self.L)]\n",
    "        self.TransformerEncoder = nn.Sequential(*transformerBlocks)\n",
    "       \n",
    "#        self.TransformerEncoder = TransformerEncoder(self.D,self.H,self.P)\n",
    "        self.mlp_head=nn.Sequential(\n",
    "            nn.Linear(self.D,self.D),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.D,self.CLS))\n",
    "\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "#        print(\"in vit \",x.shape)\n",
    "        x = self.embeddingLayer(x)\n",
    "#        print(\"in vit \",x.shape)\n",
    "        x = self.PELayer(x)\n",
    "        TF = self.TransformerEncoder(x)\n",
    "        classToken = TF[:, 0, :] \n",
    "\n",
    "        preds = self.mlp_head(classToken)\n",
    "\n",
    "        return preds\n",
    "        \n",
    "        \n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPRk2KKrySk0"
   },
   "source": [
    "# Call Model\n",
    "In this code cell setup the configuration for your model. The dimensionality of the tokens, number of heads, number of tokens etc.\n",
    "\n",
    "Note in order for your vision transformer model to be compatible with the training loops below: Check that it accepts an image batch as input and returns an output of [B,Nc] where B is the batch size and Nc are the number of classes (10) in CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1740141525167,
     "user": {
      "displayName": "Tony Scanlan",
      "userId": "11380187689366571663"
     },
     "user_tz": 0
    },
    "id": "mCAEkBIOYWzS",
    "outputId": "e1904e9e-c9ed-414e-951b-5c7104c4daad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "selfs  8 8\n",
      "torch.Size([256, 10])\n"
     ]
    }
   ],
   "source": [
    "     # Number of input Channels\n",
    "     # Transformer Dimension\n",
    "     # Numbers of heads\n",
    "     # Number of patches (input tokens)\n",
    "     # Ouptut Classes\n",
    "     # Etc\n",
    "\n",
    "numChannels=3\n",
    "numDims=32\n",
    "numPatches=16\n",
    "numHeads = 4\n",
    "numClasses=10\n",
    "numLayers = 15\n",
    "patchSize = 8\n",
    "\n",
    "\n",
    "\n",
    "model = Vision_transformer(numChannels,numDims,patchSize,numPatches,numHeads,numClasses,numLayers)\n",
    "\n",
    "# Check model can correctly process an image batch\n",
    "op=model(image_batch)\n",
    "print(op.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 10])\n"
     ]
    }
   ],
   "source": [
    "print(op.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1740141530890,
     "user": {
      "displayName": "Tony Scanlan",
      "userId": "11380187689366571663"
     },
     "user_tz": 0
    },
    "id": "H0NBFWX_e7Jy",
    "outputId": "cfbb21f6-e8ed-4474-9ad0-848fad1cff43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "aKnRVQAQHA-H"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "Vision_transformer                            [256, 10]                 --\n",
       "Patch_embedding: 1-1                        [256, 16, 32]             --\n",
       "    Conv2d: 2-1                            [256, 32, 4, 4]           6,176\n",
       "Positional_encoding: 1-2                    [256, 17, 32]             32\n",
       "Sequential: 1-3                             [256, 17, 32]             --\n",
       "    TransformerEncoder: 2-2                [256, 17, 32]             --\n",
       "        LayerNorm: 3-1                    [256, 17, 32]             64\n",
       "        MultiHeadattention: 3-2           [256, 17, 32]             864\n",
       "        LayerNorm: 3-3                    [256, 17, 32]             64\n",
       "        Sequential: 3-4                   [256, 17, 32]             2,112\n",
       "    TransformerEncoder: 2-3                [256, 17, 32]             --\n",
       "        LayerNorm: 3-5                    [256, 17, 32]             64\n",
       "        MultiHeadattention: 3-6           [256, 17, 32]             864\n",
       "        LayerNorm: 3-7                    [256, 17, 32]             64\n",
       "        Sequential: 3-8                   [256, 17, 32]             2,112\n",
       "    TransformerEncoder: 2-4                [256, 17, 32]             --\n",
       "        LayerNorm: 3-9                    [256, 17, 32]             64\n",
       "        MultiHeadattention: 3-10          [256, 17, 32]             864\n",
       "        LayerNorm: 3-11                   [256, 17, 32]             64\n",
       "        Sequential: 3-12                  [256, 17, 32]             2,112\n",
       "    TransformerEncoder: 2-5                [256, 17, 32]             --\n",
       "        LayerNorm: 3-13                   [256, 17, 32]             64\n",
       "        MultiHeadattention: 3-14          [256, 17, 32]             864\n",
       "        LayerNorm: 3-15                   [256, 17, 32]             64\n",
       "        Sequential: 3-16                  [256, 17, 32]             2,112\n",
       "    TransformerEncoder: 2-6                [256, 17, 32]             --\n",
       "        LayerNorm: 3-17                   [256, 17, 32]             64\n",
       "        MultiHeadattention: 3-18          [256, 17, 32]             864\n",
       "        LayerNorm: 3-19                   [256, 17, 32]             64\n",
       "        Sequential: 3-20                  [256, 17, 32]             2,112\n",
       "    TransformerEncoder: 2-7                [256, 17, 32]             --\n",
       "        LayerNorm: 3-21                   [256, 17, 32]             64\n",
       "        MultiHeadattention: 3-22          [256, 17, 32]             864\n",
       "        LayerNorm: 3-23                   [256, 17, 32]             64\n",
       "        Sequential: 3-24                  [256, 17, 32]             2,112\n",
       "    TransformerEncoder: 2-8                [256, 17, 32]             --\n",
       "        LayerNorm: 3-25                   [256, 17, 32]             64\n",
       "        MultiHeadattention: 3-26          [256, 17, 32]             864\n",
       "        LayerNorm: 3-27                   [256, 17, 32]             64\n",
       "        Sequential: 3-28                  [256, 17, 32]             2,112\n",
       "    TransformerEncoder: 2-9                [256, 17, 32]             --\n",
       "        LayerNorm: 3-29                   [256, 17, 32]             64\n",
       "        MultiHeadattention: 3-30          [256, 17, 32]             864\n",
       "        LayerNorm: 3-31                   [256, 17, 32]             64\n",
       "        Sequential: 3-32                  [256, 17, 32]             2,112\n",
       "    TransformerEncoder: 2-10               [256, 17, 32]             --\n",
       "        LayerNorm: 3-33                   [256, 17, 32]             64\n",
       "        MultiHeadattention: 3-34          [256, 17, 32]             864\n",
       "        LayerNorm: 3-35                   [256, 17, 32]             64\n",
       "        Sequential: 3-36                  [256, 17, 32]             2,112\n",
       "    TransformerEncoder: 2-11               [256, 17, 32]             --\n",
       "        LayerNorm: 3-37                   [256, 17, 32]             64\n",
       "        MultiHeadattention: 3-38          [256, 17, 32]             864\n",
       "        LayerNorm: 3-39                   [256, 17, 32]             64\n",
       "        Sequential: 3-40                  [256, 17, 32]             2,112\n",
       "    TransformerEncoder: 2-12               [256, 17, 32]             --\n",
       "        LayerNorm: 3-41                   [256, 17, 32]             64\n",
       "        MultiHeadattention: 3-42          [256, 17, 32]             864\n",
       "        LayerNorm: 3-43                   [256, 17, 32]             64\n",
       "        Sequential: 3-44                  [256, 17, 32]             2,112\n",
       "    TransformerEncoder: 2-13               [256, 17, 32]             --\n",
       "        LayerNorm: 3-45                   [256, 17, 32]             64\n",
       "        MultiHeadattention: 3-46          [256, 17, 32]             864\n",
       "        LayerNorm: 3-47                   [256, 17, 32]             64\n",
       "        Sequential: 3-48                  [256, 17, 32]             2,112\n",
       "    TransformerEncoder: 2-14               [256, 17, 32]             --\n",
       "        LayerNorm: 3-49                   [256, 17, 32]             64\n",
       "        MultiHeadattention: 3-50          [256, 17, 32]             864\n",
       "        LayerNorm: 3-51                   [256, 17, 32]             64\n",
       "        Sequential: 3-52                  [256, 17, 32]             2,112\n",
       "    TransformerEncoder: 2-15               [256, 17, 32]             --\n",
       "        LayerNorm: 3-53                   [256, 17, 32]             64\n",
       "        MultiHeadattention: 3-54          [256, 17, 32]             864\n",
       "        LayerNorm: 3-55                   [256, 17, 32]             64\n",
       "        Sequential: 3-56                  [256, 17, 32]             2,112\n",
       "    TransformerEncoder: 2-16               [256, 17, 32]             --\n",
       "        LayerNorm: 3-57                   [256, 17, 32]             64\n",
       "        MultiHeadattention: 3-58          [256, 17, 32]             864\n",
       "        LayerNorm: 3-59                   [256, 17, 32]             64\n",
       "        Sequential: 3-60                  [256, 17, 32]             2,112\n",
       "Sequential: 1-4                             [256, 10]                 --\n",
       "    Linear: 2-17                           [256, 32]                 1,056\n",
       "    ReLU: 2-18                             [256, 32]                 --\n",
       "    Linear: 2-19                           [256, 10]                 330\n",
       "===============================================================================================\n",
       "Total params: 54,154\n",
       "Trainable params: 54,154\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 37.57\n",
       "===============================================================================================\n",
       "Input size (MB): 3.15\n",
       "Forward/backward pass size (MB): 119.23\n",
       "Params size (MB): 0.22\n",
       "Estimated Total Size (MB): 122.59\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "# Ensure input size is correct\n",
    "model=model.to(device)\n",
    "summary(model, input_size=(batch_size, 3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3_9Lw9zOtNJ"
   },
   "source": [
    "# Optimisation & Training Loop\n",
    "\n",
    "For this classification problem we will use the  [CrossEntropy loss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html). In this pytorch function, the input is the un-normalised logit value.\n",
    "\n",
    "* The SGD (Stocasitc Gradient Descent) Optimiser with cyclic learning rate schedule is provided as a the default training configuration. You may change this in order to improve model training.\n",
    "\n",
    "* Note that you can interrupt the training if it has converged (or failed) and then view the tensorboard curves and also obtain accuracy of the test set (by running the appropriate cells).\n",
    "\n",
    "* Make sure to run the model call and optimiser call before starting training again to ensure the previous training state is cleared.\n",
    "\n",
    "[Tensorboard is imported](https://pytorch.org/tutorials/beginner/introyt/tensorboardyt_tutorial.html) to display results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "QPTIUQx5xqVJ"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt_lr = 0.004\n",
    "momentum = 0.95\n",
    "weight_decay = 0.0005\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=opt_lr, momentum=momentum, weight_decay=weight_decay) # lr=0.01\n",
    "\n",
    "#0.0005, 0.005\n",
    "lr_scheduler=torch.optim.lr_scheduler.CyclicLR(optimizer, 0.0001, 0.02,\n",
    "                                  step_size_up=2000, step_size_down=2000,\n",
    "                                  mode='triangular', gamma=1.0, scale_fn=None,\n",
    "                                  scale_mode='exp_range', cycle_momentum=True,\n",
    "                                  base_momentum=0.8, max_momentum=0.9, last_epoch=-1,\n",
    "                                  verbose='deprecated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r21Zjf3wx4Nt"
   },
   "source": [
    "Initialise Tensorboard (use of tensorboard in colab notebooks is [detailed here](https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_in_notebooks.ipynb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "fd9d6fJIx7w1"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Amend Run names based on hyperparamters and add date & time\n",
    "run_name = 'My Run'\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "log_dir = f\"runs/{run_name}_{timestamp}\"\n",
    "writer = SummaryWriter(log_dir=log_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRzXfw3K4P_L"
   },
   "source": [
    "Training & Validataion Loop (Combine into a single loop [link text](https://pytorch.org/tutorials/beginner/introyt/tensorboardyt_tutorial.html). In order to setup GUI with plots, [need to structure the naming convention](https://pytorch.org/docs/stable/tensorboard.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "SwABO9ylyP0E"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train step that operates on each batch\n",
    "def train_step(inputs, labels):\n",
    "        model.train(True)\n",
    "        # Forward Pass through Model\n",
    "        outputs = model(inputs)\n",
    "        # Calculate Loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        # perform backward step\n",
    "        loss.backward()\n",
    "        # Update optimiser and zero gradients\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        return loss, outputs\n",
    "\n",
    "# Test step that operates on each batch\n",
    "def val_step(inputs, labels):\n",
    "        model.train(False)\n",
    "        # Forward Pass through Model\n",
    "        outputs = model(inputs)\n",
    "        # Calculate Loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        return loss, outputs\n",
    "\n",
    "# Create a class to handle metrics with methods to accumulate the loss/accuracy\n",
    "# and print average over interval of iterations\n",
    "class tt_metrics:\n",
    "\n",
    "  def __init__(self,dataloader,type,n_iter=100000):\n",
    "\n",
    "        self.dataloader = dataloader\n",
    "        self.num_batches = len(dataloader)         # batches in epoch\n",
    "        self.num_samples = len(dataloader.dataset) # samples in epoch\n",
    "        self.avg_loss = 0\n",
    "        self.avg_acc = 0\n",
    "        self.type = type\n",
    "        # Determine number of iterations / samples for metric calculation\n",
    "        # number of iterations can be less than (max) iterations in an epoch\n",
    "        # max is number of iterations in epoch.\n",
    "        self.n_iter = min(n_iter,self.num_batches)\n",
    "\n",
    "        # Intialise accumulators for determining loss and accuracy\n",
    "        self.running_loss = 0.0\n",
    "        self.running_acc = 0.0\n",
    "\n",
    "  def update_acc(self, loss, outputs, labels):\n",
    "        # Accumulate loss\n",
    "        self.running_loss += loss.item()\n",
    "        # Accumulate Accuracy\n",
    "        self.running_acc += (outputs.argmax(1) == labels).type(torch.float).sum().item()\n",
    "\n",
    "  def calc_metrics(self,batch_size):\n",
    "            # Where n_iter is interval calculating average over\n",
    "            # and type is a string denoting, train val or test\n",
    "            self.avg_loss = self.running_loss / self.n_iter   # divide by number of batches are computing over\n",
    "            self.avg_acc = 100*self.running_acc / (self.n_iter*batch_size) # divide by number of examples computing accuracy over\n",
    "\n",
    "            # Reset accumulation\n",
    "            self.running_loss = 0.0\n",
    "            self.running_acc = 0.0\n",
    "\n",
    "\n",
    "def tb_write(train_metrics,val_metrics,epoch,i):\n",
    "\n",
    "      # Calculate metrics for Train & Test\n",
    "      train_metrics.calc_metrics(batch_size)\n",
    "      val_metrics.calc_metrics(batch_size)\n",
    "\n",
    "      # Print intermediate results\n",
    "      print('Epoch {}'.format(epoch),' Batch {}'.format(i + 1))\n",
    "      print(f\"{train_metrics.type} Error: \\n Accuracy: {(train_metrics.avg_acc):>0.1f}%, Avg loss: {train_metrics.avg_loss:>8f} \\n\")\n",
    "      print(f\"{val_metrics.type} Error: \\n Accuracy: {(val_metrics.avg_acc):>0.1f}%, Avg loss: {val_metrics.avg_loss:>8f} \\n\")\n",
    "\n",
    "      # Log the running loss averaged per batch\n",
    "      writer.add_scalars('Loss',\n",
    "                            { f\"{train_metrics.type}/Loss\" : train_metrics.avg_loss, f\"{val_metrics.type}/Loss\" : val_metrics.avg_loss },\n",
    "                            epoch * len(train_dataloader) + i)\n",
    "      writer.add_scalars('Accuracy',\n",
    "                            {f\"{train_metrics.type}/Accuracy\" : train_metrics.avg_acc, f\"{val_metrics.type}/Accuracy\" : val_metrics.avg_acc },\n",
    "                            epoch * len(train_dataloader) + i)\n",
    "\n",
    "\n",
    "# Main training & evaluation loop\n",
    "def train_eval_loop(model,n_epochs,n_iter):\n",
    "    # Where n_epochs is the number of epochs and n_iter can be set to\n",
    "    # a value less than number iterations in an epoch if required\n",
    "    model = model.to(device)\n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "      # Intialise metrics\n",
    "      train_metrics = tt_metrics(train_dataloader,type='Train',n_iter=100)\n",
    "      val_metrics = tt_metrics(test_dataloader,type='Test')\n",
    "\n",
    "      # Enumerate over the training data\n",
    "      for i, data in enumerate(train_dataloader, 0):\n",
    "        # Extract images and labels and transfer to device\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Run train step (returns loss outputs for metrics)\n",
    "        loss, outputs = train_step(inputs, labels)\n",
    "\n",
    "        # update metrics\n",
    "        train_metrics.update_acc(loss, outputs, labels)\n",
    "\n",
    "        # Apply learning rate scheduler\n",
    "        lr_scheduler.step()\n",
    "        # Call evaluation step after n_iter\n",
    "        if i % n_iter == n_iter-1:    # Every n mini-batches...\n",
    "\n",
    "\n",
    "            for j, vdata in enumerate(test_dataloader, 0):\n",
    "               # Extract images and labels and transfer to device\n",
    "               vinputs, vlabels = vdata\n",
    "               vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "\n",
    "               # Run train step (returns loss outputs for metrics)\n",
    "               vloss, voutputs = val_step(vinputs, vlabels)\n",
    "\n",
    "               # update metrics\n",
    "               val_metrics.update_acc(vloss, voutputs, vlabels)\n",
    "\n",
    "            # Calculate and Print metrics (metrics reset after calculation)\n",
    "            tb_write(train_metrics,val_metrics,epoch,i)\n",
    "            print('LR value = ',lr_scheduler.get_last_lr())\n",
    "\n",
    "      # Apply Schedule at end of each epoch.\n",
    "      #lr_scheduler.step(val_metrics.avg_loss)\n",
    "\n",
    "\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "fqfjZz0vKRI-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 12.6%, Avg loss: 2.311140 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 14.7%, Avg loss: 2.282620 \n",
      "\n",
      "LR value =  [0.0010949999999999966]\n",
      "Epoch 1  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 20.5%, Avg loss: 2.132443 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 22.0%, Avg loss: 2.061281 \n",
      "\n",
      "LR value =  [0.0030452000000000027]\n",
      "Epoch 2  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 26.6%, Avg loss: 1.937592 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 27.8%, Avg loss: 1.890677 \n",
      "\n",
      "LR value =  [0.0049954000000000005]\n",
      "Epoch 3  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 31.0%, Avg loss: 1.837239 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 31.4%, Avg loss: 1.813543 \n",
      "\n",
      "LR value =  [0.006945599999999998]\n",
      "Epoch 4  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 32.9%, Avg loss: 1.777276 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 33.4%, Avg loss: 1.765490 \n",
      "\n",
      "LR value =  [0.008895800000000004]\n",
      "Epoch 5  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 34.7%, Avg loss: 1.734689 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 34.7%, Avg loss: 1.729813 \n",
      "\n",
      "LR value =  [0.010846000000000001]\n",
      "Epoch 6  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 36.1%, Avg loss: 1.705034 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 36.6%, Avg loss: 1.695703 \n",
      "\n",
      "LR value =  [0.012796199999999999]\n",
      "Epoch 7  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 37.1%, Avg loss: 1.676263 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 38.4%, Avg loss: 1.644707 \n",
      "\n",
      "LR value =  [0.014746399999999996]\n",
      "Epoch 8  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 38.4%, Avg loss: 1.659411 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 38.4%, Avg loss: 1.658084 \n",
      "\n",
      "LR value =  [0.016696600000000002]\n",
      "Epoch 9  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 39.7%, Avg loss: 1.626610 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 39.6%, Avg loss: 1.610431 \n",
      "\n",
      "LR value =  [0.018646799999999998]\n",
      "Epoch 10  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 39.7%, Avg loss: 1.623671 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 37.3%, Avg loss: 1.640351 \n",
      "\n",
      "LR value =  [0.019402999999999997]\n",
      "Epoch 11  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 40.4%, Avg loss: 1.598712 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 41.0%, Avg loss: 1.603510 \n",
      "\n",
      "LR value =  [0.017452799999999997]\n",
      "Epoch 12  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 41.9%, Avg loss: 1.573229 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 40.7%, Avg loss: 1.594993 \n",
      "\n",
      "LR value =  [0.0155026]\n",
      "Epoch 13  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 42.4%, Avg loss: 1.554934 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 42.2%, Avg loss: 1.538444 \n",
      "\n",
      "LR value =  [0.013552400000000003]\n",
      "Epoch 14  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 42.9%, Avg loss: 1.539239 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 42.1%, Avg loss: 1.559131 \n",
      "\n",
      "LR value =  [0.011602200000000005]\n",
      "Epoch 15  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 43.8%, Avg loss: 1.519119 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.6%, Avg loss: 1.510445 \n",
      "\n",
      "LR value =  [0.009651999999999999]\n",
      "Epoch 16  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 44.0%, Avg loss: 1.510996 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 43.2%, Avg loss: 1.530718 \n",
      "\n",
      "LR value =  [0.007701799999999994]\n",
      "Epoch 17  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 45.4%, Avg loss: 1.486145 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.486829 \n",
      "\n",
      "LR value =  [0.0057515999999999965]\n",
      "Epoch 18  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 45.6%, Avg loss: 1.478498 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 1.480727 \n",
      "\n",
      "LR value =  [0.003801399999999999]\n",
      "Epoch 19  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 46.4%, Avg loss: 1.454499 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.0%, Avg loss: 1.494225 \n",
      "\n",
      "LR value =  [0.0018512000000000016]\n",
      "Epoch 20  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 47.3%, Avg loss: 1.438562 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 1.464341 \n",
      "\n",
      "LR value =  [0.0002989999999999958]\n",
      "Epoch 21  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 46.6%, Avg loss: 1.445706 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 1.459498 \n",
      "\n",
      "LR value =  [0.0022492000000000107]\n",
      "Epoch 22  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 46.6%, Avg loss: 1.455294 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.506685 \n",
      "\n",
      "LR value =  [0.004199399999999991]\n",
      "Epoch 23  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 46.3%, Avg loss: 1.463737 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 1.492661 \n",
      "\n",
      "LR value =  [0.006149600000000006]\n",
      "Epoch 24  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 45.9%, Avg loss: 1.472941 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.476597 \n",
      "\n",
      "LR value =  [0.008099800000000002]\n",
      "Epoch 25  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 46.0%, Avg loss: 1.475010 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 42.9%, Avg loss: 1.522320 \n",
      "\n",
      "LR value =  [0.01005]\n",
      "Epoch 26  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 45.7%, Avg loss: 1.479612 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 42.9%, Avg loss: 1.530204 \n",
      "\n",
      "LR value =  [0.012000199999999997]\n",
      "Epoch 27  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 46.1%, Avg loss: 1.475902 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.0%, Avg loss: 1.457698 \n",
      "\n",
      "LR value =  [0.013950399999999995]\n",
      "Epoch 28  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 46.5%, Avg loss: 1.463799 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 45.1%, Avg loss: 1.483150 \n",
      "\n",
      "LR value =  [0.01590060000000001]\n",
      "Epoch 29  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 46.1%, Avg loss: 1.469894 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.8%, Avg loss: 1.483368 \n",
      "\n",
      "LR value =  [0.01785079999999999]\n",
      "Epoch 30  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 46.0%, Avg loss: 1.468627 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.2%, Avg loss: 1.494449 \n",
      "\n",
      "LR value =  [0.019801000000000006]\n",
      "Epoch 31  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 47.2%, Avg loss: 1.459658 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 44.4%, Avg loss: 1.490868 \n",
      "\n",
      "LR value =  [0.0182488]\n",
      "Epoch 32  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 47.1%, Avg loss: 1.443975 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.441493 \n",
      "\n",
      "LR value =  [0.0162986]\n",
      "Epoch 33  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 47.8%, Avg loss: 1.441322 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.0%, Avg loss: 1.453951 \n",
      "\n",
      "LR value =  [0.014348400000000004]\n",
      "Epoch 34  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.428001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.6%, Avg loss: 1.428428 \n",
      "\n",
      "LR value =  [0.012398200000000007]\n",
      "Epoch 35  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 48.5%, Avg loss: 1.418326 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 1.420348 \n",
      "\n",
      "LR value =  [0.010447999999999992]\n",
      "Epoch 36  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 48.8%, Avg loss: 1.407187 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.3%, Avg loss: 1.446362 \n",
      "\n",
      "LR value =  [0.008497800000000012]\n",
      "Epoch 37  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 49.0%, Avg loss: 1.394783 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.416957 \n",
      "\n",
      "LR value =  [0.006547599999999997]\n",
      "Epoch 38  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 50.4%, Avg loss: 1.370586 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.3%, Avg loss: 1.392016 \n",
      "\n",
      "LR value =  [0.0045974]\n",
      "Epoch 39  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 50.6%, Avg loss: 1.355357 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 1.390225 \n",
      "\n",
      "LR value =  [0.0026472000000000023]\n",
      "Epoch 40  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 51.5%, Avg loss: 1.341529 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 49.3%, Avg loss: 1.370498 \n",
      "\n",
      "LR value =  [0.0006969999999999873]\n",
      "Epoch 41  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 50.7%, Avg loss: 1.354437 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.7%, Avg loss: 1.374992 \n",
      "\n",
      "LR value =  [0.0014531999999999924]\n",
      "Epoch 42  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 51.0%, Avg loss: 1.350800 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 1.378845 \n",
      "\n",
      "LR value =  [0.0034034000000000074]\n",
      "Epoch 43  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 50.5%, Avg loss: 1.369593 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 1.392194 \n",
      "\n",
      "LR value =  [0.005353600000000005]\n",
      "Epoch 44  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 50.1%, Avg loss: 1.380879 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.6%, Avg loss: 1.379159 \n",
      "\n",
      "LR value =  [0.007303800000000003]\n",
      "Epoch 45  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 49.6%, Avg loss: 1.381338 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.6%, Avg loss: 1.382894 \n",
      "\n",
      "LR value =  [0.009253999999999998]\n",
      "Epoch 46  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 50.1%, Avg loss: 1.372559 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 46.9%, Avg loss: 1.453235 \n",
      "\n",
      "LR value =  [0.011204199999999996]\n",
      "Epoch 47  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 49.2%, Avg loss: 1.389777 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 48.2%, Avg loss: 1.398483 \n",
      "\n",
      "LR value =  [0.013154399999999993]\n",
      "Epoch 48  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 49.5%, Avg loss: 1.391745 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.420783 \n",
      "\n",
      "LR value =  [0.01510459999999999]\n",
      "Epoch 49  Batch 100\n",
      "Train Error: \n",
      " Accuracy: 49.6%, Avg loss: 1.388718 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 47.5%, Avg loss: 1.421760 \n",
      "\n",
      "LR value =  [0.017054800000000005]\n"
     ]
    }
   ],
   "source": [
    "n_epochs=50\n",
    "n_iter=100\n",
    "train_eval_loop(model,n_epochs,n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhbzbvKrdKvh"
   },
   "source": [
    "Note when r[unning colab container on docker, tensorboard](https://leimao.github.io/blog/TensorBoard-On-Docker/) will open on webpage: http://127.0.0.1:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "CWWFZg3mPLU5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1153b9fcd50bd962\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1153b9fcd50bd962\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir runs --bind_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c14uQnBWqjfp"
   },
   "source": [
    "# Evaluate Model\n",
    "We will obtain the classification report after final evaluation of the test dataset with the model. A confusion matrix can also be obtained and we will plot a few example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "m1p_BCQGqk0B"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:43: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  result = getattr(asarray(obj), method)(*args, **kwds)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (39,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m    y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(np\u001b[38;5;241m.\u001b[39mreshape(store_labels,(\u001b[38;5;241m1\u001b[39m,(num_test_batches\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mbatch_size)))\n\u001b[1;32m     29\u001b[0m    \u001b[38;5;28;01mreturn\u001b[39;00m y_pred, y_true\n\u001b[0;32m---> 31\u001b[0m y_pred, y_true \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[58], line 28\u001b[0m, in \u001b[0;36meval_loop\u001b[0;34m(test_dataloader)\u001b[0m\n\u001b[1;32m     25\u001b[0m      store_labels\u001b[38;5;241m.\u001b[39mappend(label_batch)\n\u001b[1;32m     27\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(np\u001b[38;5;241m.\u001b[39mreshape(store_predictions,(\u001b[38;5;241m1\u001b[39m,(num_test_batches\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mbatch_size)))\n\u001b[0;32m---> 28\u001b[0m y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_test_batches\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred, y_true\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     52\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m, method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (39,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "store_predictions = []\n",
    "store_labels = []\n",
    "model.eval()\n",
    "\n",
    "# Evaluation loop to produce predictions for use with scikit learn confusion matrix\n",
    "def eval_loop(test_dataloader):\n",
    "\n",
    "   num_test_batches = len(test_dataloader)\n",
    "   for i, data in enumerate(test_dataloader, 0):\n",
    "      # basic test loop\n",
    "      input_batch, label_batch = data\n",
    "      input_batch = input_batch.to(device)\n",
    "\n",
    "      pred_logit = model(input_batch)\n",
    "      predictions = torch.argmax(pred_logit,1) # reduce along output dimension\n",
    "      predictions_np = predictions.to(\"cpu\").numpy()\n",
    "      label_batch_np = label_batch.numpy()\n",
    "      if i<num_test_batches-1:\n",
    "        store_predictions.append(predictions_np)\n",
    "        store_labels.append(label_batch)\n",
    "\n",
    "   y_pred = np.squeeze(np.reshape(store_predictions,(1,(num_test_batches-1)*batch_size)))\n",
    "   y_true = np.squeeze(np.reshape(store_labels,(1,(num_test_batches-1)*batch_size)))\n",
    "   return y_pred, y_true\n",
    "\n",
    "y_pred, y_true = eval_loop(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fNbE_u3qp-D"
   },
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/0.16/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "hpx7edXcqtUB"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(\u001b[43my_true\u001b[49m, y_pred, target_names\u001b[38;5;241m=\u001b[39mclasses))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hp6WRpYQqtyi"
   },
   "outputs": [],
   "source": [
    "# Output next batch from dataloader\n",
    "dataiter = iter(test_dataloader)\n",
    "image_batch, labels_batch = next(dataiter)\n",
    "\n",
    "# Pass batch through model\n",
    "model.eval()\n",
    "image_batch = image_batch.to(device)\n",
    "pred_logit = model(image_batch)\n",
    "\n",
    "\n",
    "# Use matplotlib to plot a sample of images\n",
    "import matplotlib.pyplot as plt\n",
    "i=0\n",
    "n_plots = 12 # number of plots\n",
    "f, axarr = plt.subplots(1,n_plots,figsize=(20,10))\n",
    "\n",
    "\n",
    "for image in image_batch[0:n_plots,:,:,:]:\n",
    "  disp_image =  torch.permute(image.to('cpu'),(2,1,0)).numpy() # return image to cpu for display and permute to channels last\n",
    "  mean = np.array([0.485, 0.456, 0.406])\n",
    "  std = np.array([0.229, 0.224, 0.225])\n",
    "  disp_image = std * disp_image + mean\n",
    "  disp_image = np.clip(disp_image, 0, 1)\n",
    "  axarr[i].imshow(disp_image[:,:,:])\n",
    "  axarr[i].axis(\"off\")\n",
    "  predicted, actual = classes[pred_logit[i,:].argmax(0)], classes[labels_batch[i]]\n",
    "  color = 'black' if predicted == actual else 'red'\n",
    "  axarr[i].set_title(predicted,fontsize='small', color=color)\n",
    "  i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNbwV8CwMUZT6F1ONPM/DpC",
   "provenance": [
    {
     "file_id": "1SsHG7cuQmMMKqhysgmufIyqPrLFVy3J5",
     "timestamp": 1740500380135
    },
    {
     "file_id": "1IkkVh1O7xxtoFO18nTDpCW3l99VPOAwF",
     "timestamp": 1740499620288
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
